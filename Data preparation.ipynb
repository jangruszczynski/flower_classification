{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493339e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download libraries\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to download dataset\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://www.robots.ox.ac.uk/~vgg/data/flowers/17/17flowers.tgz\"\n",
    "DATA_PATH = os.path.join(\"datasets\", \"flowers\")\n",
    "IMAGES_PATH = os.path.join(\"datasets\", \"flowers\", \"jpg\")\n",
    "def fetch_housing_data(data_url=DOWNLOAD_ROOT, data_path=DATA_PATH):\n",
    "    if not os.path.isdir(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    tgz_path = os.path.join(data_path, \"17flowers.tgz\")\n",
    "    urllib.request.urlretrieve(data_url, tgz_path)\n",
    "    data_tgz = tarfile.open(tgz_path)\n",
    "    data_tgz.extractall(path=data_path)\n",
    "    data_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39004ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data(data_url=DOWNLOAD_ROOT, data_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c0925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPARING TRAINING AND TEST DATA\n",
    "\n",
    "# assign labels to subsequent classes\n",
    "\n",
    "classes = os.listdir(IMAGES_PATH)\n",
    "#print(classes)\n",
    "\n",
    "# prepare training, validation, test data PATHS\n",
    " \n",
    "LIST_FILE_PATH = os.path.join(IMAGES_PATH, \"files.txt\")\n",
    "DATASET_PATH = os.path.join(DATA_PATH, \"prepared_dataset_1\")\n",
    "\n",
    "\n",
    "TRAINING_PATH = os.path.join(DATASET_PATH, \"training\")\n",
    "VALIDATION_PATH = os.path.join(DATASET_PATH, \"validation\")\n",
    "TEST_PATH = os.path.join(DATASET_PATH, \"test\")\n",
    "\n",
    "\n",
    "#os.mkdir(TRAINING_PATH)\n",
    "#os.mkdir(VALIDATION_PATH)\n",
    "#os.mkdir(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading list of images\n",
    "\n",
    "with open(LIST_FILE_PATH) as file:\n",
    "    all_files_list = file.readlines()\n",
    "    all_files_list = [line.rstrip() for line in all_files_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f28b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images\n",
    "\n",
    "DATASET_PATH = os.path.join(DATA_PATH, \"prepared_dataset_1\")\n",
    "\n",
    "for file_name in all_files_list:\n",
    "    \n",
    "    full_file_name = os.path.join(IMAGES_PATH, file_name)\n",
    "\n",
    "    print(full_file_name)\n",
    "    if os.path.isfile(full_file_name):\n",
    "        im = Image.open(full_file_name)\n",
    "        newsize = (224, 224)\n",
    "        im1 = im.resize(newsize)\n",
    "        display(im1)\n",
    "        im1 = im1.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3675ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "# create list of files\n",
    "\n",
    "with open(LIST_FILE_PATH, \"r\") as file:\n",
    "    file_list = file.readlines()\n",
    "    file_list = [line.rstrip() for line in lines]\n",
    "    \n",
    "# list of divisible by lenght of class\n",
    "\n",
    "list_classes = [i for i in range(1, len(list1)) if i % 80 == 0]\n",
    "list_classes\n",
    "\n",
    "# create datasets\n",
    "\n",
    "#- prepared_dataset\n",
    "#-- training\n",
    "#--- flower_1\n",
    "#--- flower_2 ...\n",
    "\n",
    "# declare location of the resized images\n",
    "\n",
    "IMAGES_PATH = os.path.join(\"datasets\", \"flowers\", \"jpg1\")\n",
    "\n",
    "\n",
    "for i in range(1,18):\n",
    "    \n",
    "    TRAIN_DIR = os.path.join(TRAINING_PATH, \"flower_{}\".format(i))\n",
    "    os.mkdir(TRAIN_DIR)\n",
    "    VAL_DIR = os.path.join(VALIDATION_PATH, \"flower_{}\".format(i))\n",
    "    os.mkdir(VAL_DIR)\n",
    "    TEST_DIR = os.path.join(TEST_PATH, \"flower_{}\".format(i))\n",
    "    os.mkdir(TEST_DIR)\n",
    "    #print(TRAIN_DIR, VAL_DIR, TEST_DIR)\n",
    "    \n",
    "    a = 80*i\n",
    "    print(a)\n",
    "    \n",
    "   \n",
    "    # list of all images in one class\n",
    "    list_total = [j for j in file_list if a-80 < int(re.search(r'\\d+', j).group()) <= a]\n",
    "    random.shuffle(list_total)\n",
    "\n",
    "    training_dataset, test_dataset = sklearn.model_selection.train_test_split(list_total, test_size=20)\n",
    "    test_dataset, valid_dataset = sklearn.model_selection.train_test_split(test_dataset, test_size=10)\n",
    "    #print(\"TRAINING\", len(training_dataset), \"VALID\", len(valid_dataset), \"TEST\", len(test_dataset))\n",
    "    #print(\"TRAINING\", training_dataset, \"VALID\", valid_dataset, \"TEST\", test_dataset)\n",
    "    \n",
    "    #copying files into subsequent datasets\n",
    "    \n",
    "    # CAN BE REPLACED WITH FUNCTION\n",
    "       \n",
    "    #training dataset\n",
    "    src_files = os.listdir(IMAGES_PATH)\n",
    "    for file_name in training_dataset:\n",
    "        full_file_name = os.path.join(IMAGES_PATH, file_name)\n",
    "        if os.path.isfile(full_file_name):\n",
    "            shutil.copy(full_file_name, TRAIN_DIR)\n",
    "    \n",
    "    #valid dataset\n",
    "    for file_name in valid_dataset:\n",
    "        full_file_name = os.path.join(IMAGES_PATH, file_name)\n",
    "        if os.path.isfile(full_file_name):\n",
    "            shutil.copy(full_file_name, VAL_DIR)\n",
    "    \n",
    "    #test dataset\n",
    "    for file_name in test_dataset:\n",
    "        full_file_name = os.path.join(IMAGES_PATH, file_name)\n",
    "        if os.path.isfile(full_file_name):\n",
    "            shutil.copy(full_file_name, TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b700280",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exploring Dataset\n",
    "\n",
    "classes = os.listdir(TRAINING_PATH)\n",
    "print(\"Total Classes: \",len(classes))\n",
    "\n",
    "#Counting total train, valid & test images\n",
    "\n",
    "train_count = 0\n",
    "valid_count = 0\n",
    "test_count = 0\n",
    "for _class in classes:\n",
    "    train_count += len(os.listdir(TRAINING_PATH + \"\\\\\" + _class))\n",
    "    valid_count += len(os.listdir(VALIDATION_PATH + \"\\\\\" +_class))\n",
    "    test_count += len(os.listdir(TEST_PATH + \"\\\\\" +_class))\n",
    "\n",
    "print(\"Total train images: \",train_count)\n",
    "print(\"Total valid images: \",valid_count)\n",
    "print(\"Total test images: \",test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = []\n",
    "valid_imgs = []\n",
    "test_imgs = []\n",
    "\n",
    "for _class in classes:\n",
    "    \n",
    "    for img in os.listdir(TRAINING_PATH + \"\\\\\" +_class):\n",
    "        train_imgs.append(TRAINING_PATH + \"\\\\\" + _class + \"\\\\\" + img)\n",
    "    \n",
    "    for img in os.listdir(VALIDATION_PATH +\"\\\\\" + _class):\n",
    "        valid_imgs.append(VALIDATION_PATH +\"\\\\\" + _class + \"\\\\\" + img)\n",
    "        \n",
    "    for img in os.listdir(TEST_PATH + \"\\\\\" + _class):\n",
    "        test_imgs.append(TEST_PATH + \"\\\\\" +_class + \"\\\\\" + img)\n",
    "\n",
    "class_to_int = {classes[i] : i for i in range(len(classes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading Classification Dataset - FOR METHOD 2: For multi-class data, by inheriting Dataset class\n",
    "\n",
    "def get_transform():\n",
    "    return T.Compose([T.ToTensor()])\n",
    "\n",
    "class FlowerDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, imgs_list, class_to_int, transforms = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.imgs_list = imgs_list\n",
    "        self.class_to_int = class_to_int\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "    \n",
    "        image_path = self.imgs_list[index]\n",
    "        \n",
    "        #Reading image\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        \n",
    "        #Retrieving class label\n",
    "        label = image_path.split(\"/\")[-2]\n",
    "        label = self.class_to_int[label]\n",
    "        \n",
    "        #Applying transforms on image\n",
    "        if self.transforms:\n",
    "            \n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, label\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
